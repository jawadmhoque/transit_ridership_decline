{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rianajawad/anaconda3/lib/python3.7/site-packages/linearmodels/panel/data.py:10: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import (Categorical, DataFrame, Index, MultiIndex, Panel, Series,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import linearmodels as lm\n",
    "import matplotlib\n",
    "import math\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from linearmodels.panel import PanelOLS\n",
    "from linearmodels.panel import RandomEffects\n",
    "from linearmodels.panel import FirstDifferenceOLS\n",
    "from linearmodels.panel import compare\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('final_estimation_file_apta_added.csv',\n",
    "                    encoding='utf-8')\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and join the maintenance and restructure data\n",
    "mr=pd.read_csv('maintenance_restructure.csv',\n",
    "                    encoding='utf-8')\n",
    "mr = mr[['CBSA', 'Mode', 'Year', 'MAINTENANCE', 'MAINTENANCE_NYC', 'MAINTENANCE_WMATA', 'RESTRUCTURE']]\n",
    "\n",
    "df = df.merge(mr, on=['CBSA', 'Mode', 'Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in mechanical and other failures\n",
    "\n",
    "failures=pd.read_csv('maintenance_final.csv',encoding='utf-8')\n",
    "\n",
    "failures.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "df=df.merge(failures, on=['CBSA','Mode','Year'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'UPT_ADJUSTED':'UPT_ADJ','VRM_ADJUSTED':'VRM_ADJ','FARE_ADJUSTED':'FARE_ADJ','AVG_FARE_2018':'FARE_per_UPT_2018'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mechanical_Failures']=df['Mechanical_Failures'].fillna(0)\n",
    "df['Total_Failures']=df['Total_Failures'].fillna(0)\n",
    "df['MDBF_Mechanical']=np.where(df['Mechanical_Failures']>0,df['VRM_ADJ']/df['Mechanical_Failures'],df['VRM_ADJ'])\n",
    "df['MDBF_Total']=np.where(df['Total_Failures']>0,df['VRM_ADJ']/df['Total_Failures'],df['VRM_ADJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and join the bike share updates\n",
    "bsu=pd.read_csv('bike_share_update.csv',\n",
    "                    encoding='utf-8')\n",
    "bsu = bsu[['CBSA', 'Mode', 'Year', 'PBS_Flag_Update']]\n",
    "\n",
    "df = df.merge(bsu, on=['CBSA', 'Mode', 'Year'], how='left')\n",
    "\n",
    "#df['PBS_Flag_Missing'] = df['PBS_Flag'].apply(lambda x : x.isnan())\n",
    "df['PBS_Flag'] = np.where(df['PBS_Flag'].isnull(), df['PBS_Flag_Update'], df['PBS_Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 apta clusers\n",
    "df['CLUSTER_APTA4'] = np.floor(df['CLUSTER_APTA']/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude if ridership is zero--missing data\n",
    "df = df[df['UPT_ADJ']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing data as needed\n",
    "\n",
    "# min fare is zero\n",
    "df['FARE_per_UPT_2018'] = df['FARE_per_UPT_2018'].apply(lambda x : max(x,0))\n",
    "\n",
    "# max fare is $20\n",
    "df['FARE_per_UPT_2018'] = df['FARE_per_UPT_2018'].apply(lambda x : min(x,20))\n",
    "\n",
    "# zero vehicle HH can't go negative\n",
    "df['HH_0Veh'] = df['HH_0Veh'].apply(lambda x : max(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 2 records with missing VRM\n",
      "Excluding 36 records with problem flag set to 1\n"
     ]
    }
   ],
   "source": [
    "# exclude problematic data\n",
    "old_len = len(df)\n",
    "df = df[df['VRM_ADJ']>0]\n",
    "new_len = len(df)\n",
    "print('Excluding ' + str(old_len-new_len) + ' records with missing VRM') \n",
    "\n",
    "# exclude if problem flag 2 is set\n",
    "old_len = len(df)\n",
    "df = df[df['PROBLEM_FLAG2']!=1]\n",
    "new_len = len(df)\n",
    "print('Excluding ' + str(old_len-new_len) + ' records with problem flag set to 1') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 1 records with discontinuities in year.\n",
      "Excluding 1 records with discontinuities in year.\n",
      "Excluding 0 records with discontinuities in year.\n"
     ]
    }
   ],
   "source": [
    "# exclude discontinuous data\n",
    "df = df.sort_values(by=['CBSA', 'Mode', 'Year'])\n",
    "\n",
    "excluded_records = 100\n",
    "while excluded_records > 0: \n",
    "    old_len = len(df)\n",
    "    df['YearDiff'] = df['Year'].shift(-1) - df['Year']\n",
    "    df = df[(df['YearDiff']==1) | (df['Year']==2018)]\n",
    "    excluded_records = old_len - len(df)\n",
    "    print('Excluding ' + str(excluded_records) + ' records with discontinuities in year.') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BUS_FLAG'] = np.where(df['Mode']=='Bus', 1, 0)\n",
    "df['RAIL_FLAG'] = np.where(df['Mode']=='Rail', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include population + employment\n",
    "df['POP_EMP'] = df['Tot_Pop'] + df['TOT_EMP_MSA']\n",
    "df['HH_EMP'] = df['Total_HH'] + df['TOT_EMP_MSA']\n",
    "\n",
    "# percent of population in transit supportive density\n",
    "df['TSD_POP_PCT'] = df['POP_CENSUSTRACT'] / df['Tot_Pop']\n",
    "\n",
    "# percent of pop born outside USA\n",
    "df['Tot_NonUSA_POP_pct'] = df['Tot_NonUSA_POP'] / df['Tot_Pop'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time effects\n",
    "df['YEARS_SINCE_2002']  = df['Year'] - 2002\n",
    "\n",
    "df['YEARS_2002_2010']  = df['Year'].apply(lambda x : min(x-2002, 8))\n",
    "df['YEARS_AFTER_2010'] = df['Year'].apply(lambda x : max(x-2010, 0))\n",
    "\n",
    "df['YEARS_2002_2014']  = df['Year'].apply(lambda x : min(x-2002, 12))\n",
    "df['YEARS_AFTER_2014'] = df['Year'].apply(lambda x : max(x-2014, 0))\n",
    "\n",
    "\n",
    "df['YEARS_SINCE_2002_BUS']  = df['YEARS_SINCE_2002'] * df['BUS_FLAG']\n",
    "df['YEARS_SINCE_2002_RAIL'] = df['YEARS_SINCE_2002'] * df['RAIL_FLAG']\n",
    "\n",
    "df['YEARS_2002_2010_BUS']   = df['YEARS_2002_2010'] * df['BUS_FLAG']\n",
    "df['YEARS_AFTER_2010_BUS']  = df['YEARS_AFTER_2010']* df['BUS_FLAG']\n",
    "df['YEARS_2002_2010_RAIL']  = df['YEARS_2002_2010'] * df['RAIL_FLAG']\n",
    "df['YEARS_AFTER_2010_RAIL'] = df['YEARS_AFTER_2010']* df['RAIL_FLAG']\n",
    "\n",
    "df['YEARS_2002_2014_BUS']   = df['YEARS_2002_2014'] * df['BUS_FLAG']\n",
    "df['YEARS_AFTER_2014_BUS']  = df['YEARS_AFTER_2014']* df['BUS_FLAG']\n",
    "df['YEARS_2002_2014_RAIL']  = df['YEARS_2002_2014'] * df['RAIL_FLAG']\n",
    "df['YEARS_AFTER_2014_RAIL'] = df['YEARS_AFTER_2014']* df['RAIL_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more time effects\n",
    "\n",
    "df['YEARS_AFTER_2012'] = df['Year'].apply(lambda x : max(x-2012, 0))\n",
    "\n",
    "df['TNC_YEARS_AFTER_2012'] = df['YEARS_AFTER_2012'] * df['TNC_FLAG']\n",
    "\n",
    "df['TNC_YEARS_AFTER_2012_BUS'] = df['TNC_YEARS_AFTER_2012'] * df['BUS_FLAG']\n",
    "df['TNC_YEARS_AFTER_2012_RAIL'] = df['TNC_YEARS_AFTER_2012'] * df['RAIL_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test rail ramp up period\n",
    "df['YEARS_SINCE_RAIL_START'] = (df['Year'] - df['min_year']) * df['RAIL_FLAG']\n",
    "df['YEARS_SINCE_RAIL_START'] = np.where(df['min_year']==2002, 0, df['YEARS_SINCE_RAIL_START'])\n",
    "\n",
    "df['YEARS_SINCE_RAIL_START_1'] = df['YEARS_SINCE_RAIL_START'].apply(lambda x : min(x, 1))\n",
    "df['YEARS_SINCE_RAIL_START_2'] = df['YEARS_SINCE_RAIL_START'].apply(lambda x : min(x, 2))\n",
    "df['YEARS_SINCE_RAIL_START_3'] = df['YEARS_SINCE_RAIL_START'].apply(lambda x : min(x, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bus vs rail stuff\n",
    "\n",
    "# various bus/rail specifics\n",
    "\n",
    "df['TNC_FLAG_BUS'] = df['TNC_FLAG'] * df['BUS_FLAG']\n",
    "df['TNC_FLAG_RAIL'] = df['TNC_FLAG'] * df['RAIL_FLAG']\n",
    "\n",
    "df['YEARS_SINCE_TNC_BUS'] = df['YEARS_SINCE_TNC'] * df['BUS_FLAG']\n",
    "df['YEARS_SINCE_TNC_RAIL'] = df['YEARS_SINCE_TNC'] * df['RAIL_FLAG']\n",
    "\n",
    "df['dockless_flag'] = df['dockCt'].apply(lambda x : min(x,1))\n",
    "df['scooter_flag']  = df['scooterCt'].apply(lambda x : min(x,1))\n",
    "\n",
    "df['BIKE_SHARE'] = df['PBS_Flag'] + df['dockless_flag']\n",
    "df['BIKE_SHARE'] = df['BIKE_SHARE'].apply(lambda x : min(x,1))\n",
    "\n",
    "\n",
    "df['PBS_Flag_BUS']   = df['PBS_Flag']   * df['BUS_FLAG']\n",
    "df['dockCt_BUS']     = df['dockCt']     * df['BUS_FLAG']\n",
    "df['docklessCt_BUS'] = df['docklessCt'] * df['BUS_FLAG']\n",
    "df['scooterCt_BUS']  = df['scooterCt']  * df['BUS_FLAG']\n",
    "df['dockless_flag_BUS'] = df['dockless_flag'] * df['BUS_FLAG']\n",
    "df['scooter_flag_BUS']  = df['scooter_flag']  * df['BUS_FLAG']\n",
    "df['BIKE_SHARE_BUS']  = df['BIKE_SHARE']  * df['BUS_FLAG']\n",
    "\n",
    "\n",
    "df['PBS_Flag_RAIL']   = df['PBS_Flag']   * df['RAIL_FLAG']\n",
    "df['dockCt_RAIL']     = df['dockCt']     * df['RAIL_FLAG']\n",
    "df['docklessCt_RAIL'] = df['docklessCt'] * df['RAIL_FLAG']\n",
    "df['scooterCt_RAIL']  = df['scooterCt']  * df['RAIL_FLAG']\n",
    "df['dockless_flag_RAIL'] = df['dockless_flag'] * df['RAIL_FLAG']\n",
    "df['scooter_flag_RAIL']  = df['scooter_flag']  * df['RAIL_FLAG']\n",
    "df['BIKE_SHARE_RAIL']  = df['BIKE_SHARE']  * df['RAIL_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert JTW to numeric columns\n",
    "df['JTW_DA_PCT']        = df['JTW_DA_PCT'].replace('#VALUE!', np.nan)\n",
    "df['JTW_CARPOOLED_PCT'] = df['JTW_CARPOOLED_PCT'].replace('#VALUE!', np.nan)\n",
    "df['JTW_TRANSIT_PCT']   = df['JTW_TRANSIT_PCT'].replace('#VALUE!', np.nan)\n",
    "df['JTW_WALK_PCT']      = df['JTW_WALK_PCT'].replace('#VALUE!', np.nan)\n",
    "df['JTW_BICYCLE_PCT']   = df['JTW_BICYCLE_PCT'].replace('#VALUE!', np.nan)\n",
    "df['JTW_OTHER_PCT']     = df['JTW_OTHER_PCT'].replace('#VALUE!', np.nan)\n",
    "df['JTW_HOME_PCT']      = df['JTW_HOME_PCT'].replace('#VALUE!', np.nan)\n",
    "\n",
    "\n",
    "df['JTW_DA_PCT']        = df['JTW_DA_PCT'].replace('N', np.nan)\n",
    "df['JTW_CARPOOLED_PCT'] = df['JTW_CARPOOLED_PCT'].replace('N', np.nan)\n",
    "df['JTW_TRANSIT_PCT']   = df['JTW_TRANSIT_PCT'].replace('N', np.nan)\n",
    "df['JTW_WALK_PCT']      = df['JTW_WALK_PCT'].replace('N', np.nan)\n",
    "df['JTW_BICYCLE_PCT']   = df['JTW_BICYCLE_PCT'].replace('N', np.nan)\n",
    "df['JTW_OTHER_PCT']     = df['JTW_OTHER_PCT'].replace('N', np.nan)\n",
    "df['JTW_HOME_PCT']      = df['JTW_HOME_PCT'].replace('N', np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert JTW to numeric columns\n",
    "df['JTW_DA_PCT']        = df['JTW_DA_PCT'].astype(float)\n",
    "df['JTW_CARPOOLED_PCT'] = df['JTW_CARPOOLED_PCT'].astype(float)\n",
    "df['JTW_TRANSIT_PCT']   = df['JTW_TRANSIT_PCT'].astype(float)\n",
    "df['JTW_WALK_PCT']      = df['JTW_WALK_PCT'].astype(float)\n",
    "df['JTW_BICYCLE_PCT']   = df['JTW_BICYCLE_PCT'].astype(float)\n",
    "df['JTW_OTHER_PCT']     = df['JTW_OTHER_PCT'].astype(float)\n",
    "df['JTW_HOME_PCT']      = df['JTW_HOME_PCT'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# immigrant population percentage\n",
    "df['Tot_NonUSA_POP_pct'] = df['Tot_NonUSA_POP'] / df['Tot_Pop'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bike share plus scooters for rail\n",
    "df['BIKE_SCOOTER_RAIL'] = df['BIKE_SHARE_RAIL'] + df['scooter_flag_RAIL']\n",
    "\n",
    "# different spec of bike and scooter\n",
    "df['BIKE_SCOOTER_SCOOTER_RAIL'] = df['BIKE_SHARE_RAIL'] + df['scooter_flag_RAIL'] + df['scooter_flag_RAIL']\n",
    "\n",
    "# different spec of bike and scooter\n",
    "df['BIKE_SCOOTER_SCOOTER_RAIL'] = df['BIKE_SHARE_RAIL'] + df['scooter_flag_RAIL'] + df['scooter_flag_RAIL']\n",
    "\n",
    "# merge bike and scooter for bus\n",
    "df['BIKE_SCOOTER_SCOOTER_BUS'] = df['BIKE_SHARE_BUS'] + df['scooter_flag_BUS'] + df['scooter_flag_BUS']\n",
    "\n",
    "# merge bike and scooter for bus\n",
    "df['BIKE_SCOOTER_BUS'] = df['BIKE_SHARE_BUS'] + df['scooter_flag_BUS'] \n",
    "df['BIKE_SCOOTER_RAIL'] = df['BIKE_SHARE_RAIL'] + df['scooter_flag_RAIL'] \n",
    "\n",
    "# scooter or bike\n",
    "df['BIKE_OR_SCOOTER_BUS']  = df['BIKE_SHARE_BUS'] + df['scooter_flag_BUS'] \n",
    "df['BIKE_OR_SCOOTER_BUS']  = df['BIKE_OR_SCOOTER_BUS'].apply(lambda x : min(x, 1))\n",
    "\n",
    "df['BIKE_OR_SCOOTER_RAIL'] = df['BIKE_SHARE_RAIL'] + df['scooter_flag_RAIL'] \n",
    "df['BIKE_OR_SCOOTER_RAIL'] = df['BIKE_OR_SCOOTER_RAIL'].apply(lambda x : min(x, 1))\n",
    "\n",
    "# calculate average vehicles\n",
    "df['AVG_VEHS'] = (df['HH_1Veh'] + 2*df['HH_2Veh'] + 3*df['HH_3Veh'] + 4*df['HH_4+Veh']) / (df['HH_0Veh'] + df['HH_1Veh'] + df['HH_2Veh'] + df['HH_3Veh'] + df['HH_4+Veh'])\n",
    "df['AVG_VEHS_log'] = np.log(1+df['AVG_VEHS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk bike other commuting\n",
    "df['JTW_WALK_BIKE_OTHER_PCT'] = df['JTW_WALK_PCT'] + df['JTW_BICYCLE_PCT'] + df['JTW_OTHER_PCT']\n",
    "\n",
    "# walk bike commuting\n",
    "df['JTW_WALK_BIKE_PCT'] = df['JTW_WALK_PCT'] + df['JTW_BICYCLE_PCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VRM_ADJ_BUS'] = df['VRM_ADJ'] * df['BUS_FLAG']\n",
    "df['VRM_ADJ_RAIL'] = df['VRM_ADJ'] * df['RAIL_FLAG']\n",
    "\n",
    "\n",
    "#maintenance effect on competing mode\n",
    "df['MDBF_Mechanical_RAIL']  = df['MDBF_Mechanical'] * df['RAIL_FLAG']\n",
    "df['MDBF_Mechanical_BUS'] = df['MDBF_Mechanical']  * df['BUS_FLAG']\n",
    "\n",
    "df['MDBF_Total_RAIL']  = df['MDBF_Total'] * df['RAIL_FLAG']\n",
    "df['MDBF_Total_BUS'] = df['MDBF_Total']  * df['BUS_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment TNCs by cluster\n",
    "df['HI_OPEX']  = np.where(df['CLUSTER_APTA4']==1, 1, 0)\n",
    "df['MID_OPEX'] = np.where(df['CLUSTER_APTA4']==2, 1, 0)\n",
    "df['LOW_OPEX'] = np.where(df['CLUSTER_APTA4']==3, 1, 0)\n",
    "df['NEW_YORK'] = np.where(df['CLUSTER_APTA4']==10, 1, 0)\n",
    "\n",
    "df['YEARS_SINCE_TNC_BUS_HI']  = df['YEARS_SINCE_TNC_BUS'] * df['HI_OPEX']\n",
    "df['YEARS_SINCE_TNC_BUS_MID'] = df['YEARS_SINCE_TNC_BUS'] * df['MID_OPEX']\n",
    "df['YEARS_SINCE_TNC_BUS_LOW'] = df['YEARS_SINCE_TNC_BUS'] * df['LOW_OPEX']\n",
    "df['YEARS_SINCE_TNC_BUS_NY']  = df['YEARS_SINCE_TNC_BUS'] * df['NEW_YORK']\n",
    "\n",
    "df['YEARS_SINCE_TNC_RAIL_HI']  = df['YEARS_SINCE_TNC_RAIL'] * df['HI_OPEX']\n",
    "df['YEARS_SINCE_TNC_RAIL_MID'] = df['YEARS_SINCE_TNC_RAIL'] * df['MID_OPEX']\n",
    "df['YEARS_SINCE_TNC_RAIL_LOW'] = df['YEARS_SINCE_TNC_RAIL'] * df['LOW_OPEX']\n",
    "df['YEARS_SINCE_TNC_RAIL_NY']  = df['YEARS_SINCE_TNC_RAIL'] * df['NEW_YORK']\n",
    "\n",
    "df['YEARS_SINCE_TNC_BUS_HINY']  = df['YEARS_SINCE_TNC_BUS_HI'] + df['YEARS_SINCE_TNC_BUS_NY']\n",
    "df['YEARS_SINCE_TNC_RAIL_HINY']  = df['YEARS_SINCE_TNC_RAIL_HI'] + df['YEARS_SINCE_TNC_RAIL_NY']\n",
    "\n",
    "df['YEARS_SINCE_TNC_BUS_MIDLOW']  = df['YEARS_SINCE_TNC_BUS_MID'] + df['YEARS_SINCE_TNC_BUS_LOW']\n",
    "df['YEARS_SINCE_TNC_RAIL_MIDLOW']  = df['YEARS_SINCE_TNC_RAIL_MID'] + df['YEARS_SINCE_TNC_RAIL_LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bikes and scooters by segment\n",
    "\n",
    "df['BIKE_SHARE_HI']  = df['BIKE_SHARE'] * df['HI_OPEX']\n",
    "df['BIKE_SHARE_MID'] = df['BIKE_SHARE'] * df['MID_OPEX']\n",
    "df['BIKE_SHARE_LOW'] = df['BIKE_SHARE'] * df['LOW_OPEX']\n",
    "df['BIKE_SHARE_NY']  = df['BIKE_SHARE'] * df['NEW_YORK']\n",
    "\n",
    "df['scooter_flag_HI']  = df['scooter_flag'] * df['HI_OPEX']\n",
    "df['scooter_flag_MID'] = df['scooter_flag'] * df['MID_OPEX']\n",
    "df['scooter_flag_LOW'] = df['scooter_flag'] * df['LOW_OPEX']\n",
    "df['scooter_flag_NY']  = df['scooter_flag'] * df['NEW_YORK']\n",
    "\n",
    "\n",
    "df['BIKE_SHARE_HINY']  = df['BIKE_SHARE_HI'] + df['BIKE_SHARE_NY']\n",
    "df['BIKE_SHARE_MIDLOW']  = df['BIKE_SHARE_MID'] + df['BIKE_SHARE_LOW']\n",
    "\n",
    "df['scooter_flag_HINY']  = df['scooter_flag_HI'] + df['scooter_flag_NY']\n",
    "df['scooter_flag_MIDLOW']  = df['scooter_flag_MID'] + df['scooter_flag_LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the indices\n",
    "df['ID'] = df['MNAME'] + '-' + df['Mode']\n",
    "df=df.set_index(['ID','Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the numeric columns -- the estimation will give an error otherwise\n",
    "df = df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rianajawad/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/rianajawad/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create a log of all fields\n",
    "for col in df.columns:\n",
    "    df[col+'_log'] = np.log(df[col]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TNC ramp up\n",
    "\n",
    "df['YEARS_SINCE_TNC_BUS_2'] = df['YEARS_SINCE_TNC_BUS'].apply(lambda x : min(x, 2))\n",
    "df['YEARS_SINCE_TNC_BUS_3'] = df['YEARS_SINCE_TNC_BUS'].apply(lambda x : min(x, 3))\n",
    "df['YEARS_SINCE_TNC_BUS_4'] = df['YEARS_SINCE_TNC_BUS'].apply(lambda x : min(x, 4))\n",
    "df['YEARS_SINCE_TNC_BUS_5'] = df['YEARS_SINCE_TNC_BUS'].apply(lambda x : min(x, 5))\n",
    "\n",
    "df['YEARS_SINCE_TNC_RAIL_2'] = df['YEARS_SINCE_TNC_RAIL'].apply(lambda x : min(x, 2))\n",
    "df['YEARS_SINCE_TNC_RAIL_3'] = df['YEARS_SINCE_TNC_RAIL'].apply(lambda x : min(x, 3))\n",
    "df['YEARS_SINCE_TNC_RAIL_4'] = df['YEARS_SINCE_TNC_RAIL'].apply(lambda x : min(x, 4))\n",
    "df['YEARS_SINCE_TNC_RAIL_5'] = df['YEARS_SINCE_TNC_RAIL'].apply(lambda x : min(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the first year of TNC presence\n",
    "df['YEARS_SINCE_TNC_BUS2'] = df['YEARS_SINCE_TNC_BUS'] + df['TNC_FLAG_BUS']\n",
    "df['YEARS_SINCE_TNC_RAIL2'] = df['YEARS_SINCE_TNC_RAIL'] + df['TNC_FLAG_RAIL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start in first year TNCs show up\n",
    "\n",
    "df['YEARS_SINCE_TNC_BUS2_NY']  = df['YEARS_SINCE_TNC_BUS2'] * df['NEW_YORK']\n",
    "df['YEARS_SINCE_TNC_BUS2_HI']  = df['YEARS_SINCE_TNC_BUS2'] * df['HI_OPEX']\n",
    "df['YEARS_SINCE_TNC_BUS2_MID'] = df['YEARS_SINCE_TNC_BUS2'] * df['MID_OPEX']\n",
    "df['YEARS_SINCE_TNC_BUS2_LOW'] = df['YEARS_SINCE_TNC_BUS2'] * df['LOW_OPEX']\n",
    "\n",
    "df['YEARS_SINCE_TNC_BUS2_HINY']   = df['YEARS_SINCE_TNC_BUS2_NY'] + df['YEARS_SINCE_TNC_BUS2_HI']\n",
    "df['YEARS_SINCE_TNC_BUS2_MIDLOW'] = df['YEARS_SINCE_TNC_BUS2_MID'] + df['YEARS_SINCE_TNC_BUS2_LOW']\n",
    "\n",
    "df['YEARS_SINCE_TNC_RAIL2_NY']  = df['YEARS_SINCE_TNC_RAIL2'] * df['NEW_YORK']\n",
    "df['YEARS_SINCE_TNC_RAIL2_HI']  = df['YEARS_SINCE_TNC_RAIL2'] * df['HI_OPEX']\n",
    "df['YEARS_SINCE_TNC_RAIL2_MID'] = df['YEARS_SINCE_TNC_RAIL2'] * df['MID_OPEX']\n",
    "df['YEARS_SINCE_TNC_RAIL2_LOW'] = df['YEARS_SINCE_TNC_RAIL2'] * df['LOW_OPEX']\n",
    "\n",
    "df['YEARS_SINCE_TNC_RAIL2_HINY']   = df['YEARS_SINCE_TNC_RAIL2_NY'] + df['YEARS_SINCE_TNC_RAIL2_HI']\n",
    "df['YEARS_SINCE_TNC_RAIL2_MIDLOW'] = df['YEARS_SINCE_TNC_RAIL2_MID'] + df['YEARS_SINCE_TNC_RAIL2_LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BIKE SHARE SEGMENTATION\n",
    "\n",
    "df['BIKE_SHARE_NY']  = df['BIKE_SHARE'] * df['NEW_YORK']\n",
    "df['BIKE_SHARE_HI']  = df['BIKE_SHARE'] * df['HI_OPEX']\n",
    "df['BIKE_SHARE_MID'] = df['BIKE_SHARE'] * df['MID_OPEX']\n",
    "df['BIKE_SHARE_LOW'] = df['BIKE_SHARE'] * df['LOW_OPEX']\n",
    "\n",
    "df['BIKE_SHARE_HINY']   = df['BIKE_SHARE_NY'] + df['BIKE_SHARE_HI']\n",
    "df['BIKE_SHARE_MIDLOW'] = df['BIKE_SHARE_MID'] + df['BIKE_SHARE_LOW']\n",
    "\n",
    "df['scooter_flag_NY']  = df['scooter_flag'] * df['NEW_YORK']\n",
    "df['scooter_flag_HI']  = df['scooter_flag'] * df['HI_OPEX']\n",
    "df['scooter_flag_MID'] = df['scooter_flag'] * df['MID_OPEX']\n",
    "df['scooter_flag_LOW'] = df['scooter_flag'] * df['LOW_OPEX']\n",
    "\n",
    "df['scooter_flag_HINY']   = df['scooter_flag_NY'] + df['scooter_flag_HI']\n",
    "df['scooter_flag_MIDLOW'] = df['scooter_flag_MID'] + df['scooter_flag_LOW']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:            UPT_ADJ_log   R-squared:                        0.6292\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.9408\n",
      "No. Observations:                4145   R-squared (Within):               0.6292\n",
      "Date:                Mon, Mar 23 2020   R-squared (Overall):              0.9416\n",
      "Time:                        07:44:50   Log-likelihood                    1314.5\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      436.48\n",
      "Entities:                         272   P-value                           0.0000\n",
      "Avg Obs:                       15.239   Distribution:                 F(15,3858)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       17.000   F-statistic (robust):             436.48\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                      17   Distribution:                 F(15,3858)\n",
      "Avg Obs:                       243.82                                           \n",
      "Min Obs:                       164.00                                           \n",
      "Max Obs:                       267.00                                           \n",
      "                                                                                \n",
      "                                      Parameter Estimates                                       \n",
      "================================================================================================\n",
      "                              Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------\n",
      "VRM_ADJ_log                      0.8150     0.0127     63.983     0.0000      0.7900      0.8399\n",
      "FARE_per_UPT_2018_log           -0.6564     0.0201    -32.668     0.0000     -0.6958     -0.6170\n",
      "POP_EMP_log                      0.2068     0.0528     3.9149     0.0001      0.1032      0.3103\n",
      "GAS_PRICE_2018_log               0.2165     0.0258     8.4029     0.0000      0.1660      0.2671\n",
      "TOTAL_MED_INC_INDIV_2018_log    -0.3524     0.0530    -6.6543     0.0000     -0.4562     -0.2485\n",
      "PCT_HH_NO_VEH                    0.0069     0.0030     2.2946     0.0218      0.0010      0.0128\n",
      "WEIGHTED_POP_DENSITY             0.0002   3.96e-05     4.5267     0.0000      0.0001      0.0003\n",
      "JTW_HOME_PCT                     0.0010     0.0039     0.2453     0.8062     -0.0068      0.0087\n",
      "YEARS_SINCE_TNC_BUS2_HINY       -0.0195     0.0057    -3.4162     0.0006     -0.0307     -0.0083\n",
      "YEARS_SINCE_TNC_BUS2_MIDLOW     -0.0177     0.0036    -4.9330     0.0000     -0.0247     -0.0106\n",
      "YEARS_SINCE_TNC_RAIL2_HINY      -0.0134     0.0058    -2.3087     0.0210     -0.0247     -0.0020\n",
      "YEARS_SINCE_TNC_RAIL2_MIDLOW    -0.0162     0.0071    -2.2778     0.0228     -0.0301     -0.0023\n",
      "BIKE_SHARE                       0.0022     0.0130     0.1658     0.8683     -0.0233      0.0276\n",
      "MDBF_Total_log                  -0.0112     0.0033    -3.4165     0.0006     -0.0177     -0.0048\n",
      "scooter_flag                    -0.0683     0.0255    -2.6750     0.0075     -0.1183     -0.0182\n",
      "================================================================================================\n",
      "\n",
      "F-test for Poolability: 122.54\n",
      "P-value: 0.0000\n",
      "Distribution: F(271,3858)\n",
      "\n",
      "Included effects: Entity\n"
     ]
    }
   ],
   "source": [
    "mod=PanelOLS.from_formula('UPT_ADJ_log \\\n",
    "                    ~ VRM_ADJ_log \\\n",
    "                    + FARE_per_UPT_2018_log \\\n",
    "                    + POP_EMP_log \\\n",
    "                    + GAS_PRICE_2018_log \\\n",
    "                    + TOTAL_MED_INC_INDIV_2018_log \\\n",
    "                    + PCT_HH_NO_VEH \\\n",
    "                    + WEIGHTED_POP_DENSITY \\\n",
    "                    + JTW_HOME_PCT \\\n",
    "                    + YEARS_SINCE_TNC_BUS2_HINY \\\n",
    "                    + YEARS_SINCE_TNC_BUS2_MIDLOW \\\n",
    "                    + YEARS_SINCE_TNC_RAIL2_HINY \\\n",
    "                    + YEARS_SINCE_TNC_RAIL2_MIDLOW \\\n",
    "                    + BIKE_SHARE \\\n",
    "                    + MDBF_Total_log \\\n",
    "                    + scooter_flag \\\n",
    "                    + EntityEffects \\\n",
    "                    ',data=df)\n",
    "res=mod.fit()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:            UPT_ADJ_log   R-squared:                        0.6311\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.9724\n",
      "No. Observations:                4145   R-squared (Within):               0.6311\n",
      "Date:                Mon, Mar 23 2020   R-squared (Overall):              0.9729\n",
      "Time:                        07:41:22   Log-likelihood                    1324.9\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      439.98\n",
      "Entities:                         272   P-value                           0.0000\n",
      "Avg Obs:                       15.239   Distribution:                 F(15,3858)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       17.000   F-statistic (robust):             439.98\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                      17   Distribution:                 F(15,3858)\n",
      "Avg Obs:                       243.82                                           \n",
      "Min Obs:                       164.00                                           \n",
      "Max Obs:                       267.00                                           \n",
      "                                                                                \n",
      "                                      Parameter Estimates                                       \n",
      "================================================================================================\n",
      "                              Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------\n",
      "VRM_ADJ_log                      0.8116     0.0127     63.830     0.0000      0.7867      0.8365\n",
      "FARE_per_UPT_2018_log           -0.6605     0.0201    -32.922     0.0000     -0.6998     -0.6211\n",
      "POP_EMP_log                      0.1399     0.0546     2.5616     0.0105      0.0328      0.2470\n",
      "GAS_PRICE_2018_log               0.2269     0.0258     8.7935     0.0000      0.1763      0.2774\n",
      "TOTAL_MED_INC_INDIV_2018_log    -0.3594     0.0528    -6.8029     0.0000     -0.4629     -0.2558\n",
      "PCT_HH_NO_VEH                    0.0071     0.0030     2.3518     0.0187      0.0012      0.0129\n",
      "WEIGHTED_POP_DENSITY_log         0.9834     0.1554     6.3262     0.0000      0.6786      1.2882\n",
      "JTW_HOME_PCT                 -2.754e-05     0.0039    -0.0070     0.9944     -0.0077      0.0077\n",
      "YEARS_SINCE_TNC_BUS2_HINY       -0.0133     0.0050    -2.6482     0.0081     -0.0232     -0.0035\n",
      "YEARS_SINCE_TNC_BUS2_MIDLOW     -0.0180     0.0036    -5.0356     0.0000     -0.0250     -0.0110\n",
      "YEARS_SINCE_TNC_RAIL2_HINY      -0.0069     0.0051    -1.3455     0.1785     -0.0169      0.0031\n",
      "YEARS_SINCE_TNC_RAIL2_MIDLOW    -0.0168     0.0071    -2.3764     0.0175     -0.0307     -0.0029\n",
      "BIKE_SHARE                       0.0017     0.0130     0.1340     0.8934     -0.0237      0.0272\n",
      "MDBF_Total_log                  -0.0112     0.0033    -3.4286     0.0006     -0.0177     -0.0048\n",
      "scooter_flag                    -0.0751     0.0255    -2.9455     0.0032     -0.1251     -0.0251\n",
      "================================================================================================\n",
      "\n",
      "F-test for Poolability: 110.56\n",
      "P-value: 0.0000\n",
      "Distribution: F(271,3858)\n",
      "\n",
      "Included effects: Entity\n"
     ]
    }
   ],
   "source": [
    "mod=PanelOLS.from_formula('UPT_ADJ_log \\\n",
    "                    ~ VRM_ADJ_log \\\n",
    "                    + FARE_per_UPT_2018_log \\\n",
    "                    + POP_EMP_log \\\n",
    "                    + GAS_PRICE_2018_log \\\n",
    "                    + TOTAL_MED_INC_INDIV_2018_log \\\n",
    "                    + PCT_HH_NO_VEH \\\n",
    "                    + WEIGHTED_POP_DENSITY_log \\\n",
    "                    + JTW_HOME_PCT \\\n",
    "                    + YEARS_SINCE_TNC_BUS2_HINY \\\n",
    "                    + YEARS_SINCE_TNC_BUS2_MIDLOW \\\n",
    "                    + YEARS_SINCE_TNC_RAIL2_HINY \\\n",
    "                    + YEARS_SINCE_TNC_RAIL2_MIDLOW \\\n",
    "                    + BIKE_SHARE \\\n",
    "                    + MDBF_Total_log \\\n",
    "                    + scooter_flag \\\n",
    "                    + EntityEffects \\\n",
    "                    ',data=df)\n",
    "res=mod.fit()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_mode(df):\n",
    "    if (df['BIKE_SHARE']==1) or (df['scooter_flag']==1) or (df['TNC_FLAG']==1):\n",
    "        x=1\n",
    "    else:\n",
    "        x=0\n",
    "    return x\n",
    "    \n",
    "df['ALT_MODE']=df.apply(alt_mode,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FAILURE_ALT_MODE_INTERACTION']=df['ALT_MODE']*df['MDBF_Total']\n",
    "df['FAILURE_ALT_MODE_INTERACTION_log'] = np.log(df['FAILURE_ALT_MODE_INTERACTION']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:            UPT_ADJ_log   R-squared:                        0.6286\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.9389\n",
      "No. Observations:                4145   R-squared (Within):               0.6286\n",
      "Date:                Mon, Mar 23 2020   R-squared (Overall):              0.9396\n",
      "Time:                        07:29:47   Log-likelihood                    1311.0\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      435.30\n",
      "Entities:                         272   P-value                           0.0000\n",
      "Avg Obs:                       15.239   Distribution:                 F(15,3858)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       17.000   F-statistic (robust):             435.30\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                      17   Distribution:                 F(15,3858)\n",
      "Avg Obs:                       243.82                                           \n",
      "Min Obs:                       164.00                                           \n",
      "Max Obs:                       267.00                                           \n",
      "                                                                                \n",
      "                                        Parameter Estimates                                         \n",
      "====================================================================================================\n",
      "                                  Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "----------------------------------------------------------------------------------------------------\n",
      "VRM_ADJ_log                          0.8094     0.0128     63.454     0.0000      0.7844      0.8344\n",
      "FARE_per_UPT_2018_log               -0.6521     0.0200    -32.530     0.0000     -0.6914     -0.6128\n",
      "POP_EMP_log                          0.1976     0.0535     3.6935     0.0002      0.0927      0.3025\n",
      "WEIGHTED_POP_DENSITY                 0.0002  3.967e-05     4.6448     0.0000      0.0001      0.0003\n",
      "GAS_PRICE_2018_log                   0.2227     0.0260     8.5539     0.0000      0.1717      0.2738\n",
      "TOTAL_MED_INC_INDIV_2018_log        -0.3511     0.0533    -6.5860     0.0000     -0.4556     -0.2466\n",
      "PCT_HH_NO_VEH                        0.0072     0.0030     2.3845     0.0172      0.0013      0.0131\n",
      "JTW_HOME_PCT                         0.0011     0.0039     0.2660     0.7902     -0.0067      0.0088\n",
      "YEARS_SINCE_TNC_BUS2_HINY           -0.0236     0.0059    -3.9775     0.0001     -0.0352     -0.0120\n",
      "YEARS_SINCE_TNC_BUS2_MIDLOW         -0.0240     0.0044    -5.3930     0.0000     -0.0327     -0.0153\n",
      "YEARS_SINCE_TNC_RAIL2_HINY          -0.0174     0.0061    -2.8708     0.0041     -0.0293     -0.0055\n",
      "YEARS_SINCE_TNC_RAIL2_MIDLOW        -0.0203     0.0075    -2.7179     0.0066     -0.0349     -0.0056\n",
      "BIKE_SHARE                          -0.0020     0.0132    -0.1528     0.8786     -0.0278      0.0238\n",
      "scooter_flag                        -0.0557     0.0260    -2.1402     0.0324     -0.1068     -0.0047\n",
      "FAILURE_ALT_MODE_INTERACTION_log     0.0030     0.0013     2.2546     0.0242      0.0004      0.0057\n",
      "====================================================================================================\n",
      "\n",
      "F-test for Poolability: 123.19\n",
      "P-value: 0.0000\n",
      "Distribution: F(271,3858)\n",
      "\n",
      "Included effects: Entity\n"
     ]
    }
   ],
   "source": [
    "mod=PanelOLS.from_formula('UPT_ADJ_log \\\n",
    "                    ~ VRM_ADJ_log \\\n",
    "                    + FARE_per_UPT_2018_log \\\n",
    "                    + POP_EMP_log \\\n",
    "                    + WEIGHTED_POP_DENSITY \\\n",
    "                    + GAS_PRICE_2018_log \\\n",
    "                    + TOTAL_MED_INC_INDIV_2018_log \\\n",
    "                    + PCT_HH_NO_VEH \\\n",
    "                    + JTW_HOME_PCT \\\n",
    "                    + YEARS_SINCE_TNC_BUS2_HINY \\\n",
    "                    + YEARS_SINCE_TNC_BUS2_MIDLOW \\\n",
    "                    + YEARS_SINCE_TNC_RAIL2_HINY \\\n",
    "                    + YEARS_SINCE_TNC_RAIL2_MIDLOW \\\n",
    "                    + BIKE_SHARE \\\n",
    "                    + scooter_flag \\\n",
    "                    + FAILURE_ALT_MODE_INTERACTION_log \\\n",
    "                    + EntityEffects \\\n",
    "                    ',data=df)\n",
    "res=mod.fit()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate FAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the relevant fields in the data set\n",
    "app_data = pd.concat([df[['RAIL_FLAG', 'CLUSTER_APTA']], \n",
    "                      res.model.dependent.dataframe, \n",
    "                      res.model.exog.dataframe, \n",
    "                      res.estimated_effects, \n",
    "                      res.resids], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the fitted values\n",
    "app_data['fitted'] = app_data['estimated_effects']\n",
    "for var in res.params.keys(): \n",
    "    app_data['fitted'] = app_data['fitted'] + (res.params[var] * app_data[var])\n",
    "\n",
    "# and check that we add up correctly\n",
    "app_data['check_fitted'] = app_data['fitted'] + app_data['residual'] - app_data['UPT_ADJ_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the necessary columns\n",
    "\n",
    "# dependents\n",
    "app_data['UPT_ADJ']    = np.exp(app_data['UPT_ADJ_log']) - 1\n",
    "app_data['fitted_exp'] = np.exp(app_data['fitted']) - 1\n",
    "\n",
    "# linear versions of logged variables\n",
    "for var in res.params.keys(): \n",
    "    if '_log' in var: \n",
    "        app_data[var.replace('_log', '')] = np.exp(app_data[var]) - 1              \n",
    "\n",
    "# ratios and differences\n",
    "for var in res.params.keys(): \n",
    "    if '_log' in var: \n",
    "        app_data[var.replace('_log', '_ratio')] = 1\n",
    "    else: \n",
    "        app_data[var+'_diff'] = 0\n",
    "\n",
    "# FAC multipliers\n",
    "for var in res.params.keys(): \n",
    "    app_data[var+'_FAC_ratio'] = 1\n",
    "\n",
    "app_data['UPT_ADJ_base'] = 0\n",
    "app_data['UPT_ADJ_ratio'] = 1\n",
    "app_data['fitted_exp_ratio'] = 1\n",
    "app_data['UPT_ADJ_diff'] = 0\n",
    "app_data['fitted_exp_diff'] = 0\n",
    "\n",
    "# for tracking new systems\n",
    "app_data['UPT_ADJ_first_year'] = 0\n",
    "app_data['UPT_ADJ_new_reporter'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ridership in the first year the system starts. This allows us to track new systems. \n",
    "# calculate the FAC relative to a specific base year\n",
    "ids = app_data.index.get_level_values(0).unique()\n",
    "\n",
    "for id in ids: \n",
    "    years = app_data.loc[id].index.get_level_values(0).sort_values()\n",
    "    first_year = years[0]\n",
    "\n",
    "    app_data.loc[(id,first_year),'UPT_ADJ_new_reporter'] = app_data.loc[(id,first_year),'UPT_ADJ']\n",
    "    \n",
    "    for year in years: \n",
    "        app_data.loc[(id,year),'UPT_ADJ_first_year']   = app_data.loc[(id,first_year),'UPT_ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rianajawad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/rianajawad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# calculate the FAC relative to a specific base year\n",
    "ids = app_data.index.get_level_values(0).unique()\n",
    "\n",
    "for id in ids: \n",
    "    years = app_data.loc[id].index.get_level_values(0).sort_values()\n",
    "\n",
    "    for year in years[1:]:       \n",
    "        base_year = year-1\n",
    "        \n",
    "        for var in res.params.keys(): \n",
    "            # ratios and differences\n",
    "            if '_log' in var: \n",
    "                out_var = var.replace('_log', '_ratio')\n",
    "                app_data.loc[(id,year), out_var] = (app_data.loc[(id,year), var] \n",
    "                                                 / app_data.loc[(id,base_year), var])\n",
    "            else: \n",
    "                out_var = var+'_diff'                    \n",
    "                app_data.loc[(id,year), out_var] = (app_data.loc[(id,year), var] \n",
    "                                                 - app_data.loc[(id,base_year), var])\n",
    "\n",
    "            # FAC multipliers\n",
    "            app_data.loc[(id,year),var+'_FAC_ratio'] = np.exp(res.params[var] * (\n",
    "                                                    app_data.loc[(id,year), var] \n",
    "                                                    - app_data.loc[(id,base_year), var]))\n",
    "\n",
    "            # estimated effects (if time effects is zero, no change)\n",
    "            app_data.loc[(id,year),'effects_FAC_ratio'] = np.exp(\n",
    "                                                    app_data.loc[(id,year), 'estimated_effects'] \n",
    "                                                    - app_data.loc[(id,base_year), 'estimated_effects'])\n",
    "\n",
    "            # residual\n",
    "            app_data.loc[(id,year),'residual_FAC_ratio'] = np.exp(\n",
    "                                                    app_data.loc[(id,year), 'residual'] \n",
    "                                                    - app_data.loc[(id,base_year), 'residual'])\n",
    "\n",
    "        # observed and fitted changes            \n",
    "        app_data.loc[(id,year),'UPT_ADJ_base'] = app_data.loc[(id,base_year),'UPT_ADJ']\n",
    "        app_data.loc[(id,year),'UPT_ADJ_ratio'] = (app_data.loc[(id,year),'UPT_ADJ'] \n",
    "                                                 / app_data.loc[(id,base_year),'UPT_ADJ'])\n",
    "        app_data.loc[(id,year),'fitted_exp_ratio'] = (app_data.loc[(id,year),'fitted_exp'] \n",
    "                                                 / app_data.loc[(id,base_year),'fitted_exp'])\n",
    "\n",
    "        app_data.loc[(id,year),'UPT_ADJ_diff'] = (app_data.loc[(id,year),'UPT_ADJ'] \n",
    "                                                 - app_data.loc[(id,base_year),'UPT_ADJ'])\n",
    "        app_data.loc[(id,year),'fitted_exp_diff'] = (app_data.loc[(id,year),'fitted_exp'] \n",
    "                                                 - app_data.loc[(id,base_year),'fitted_exp'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the FAC\n",
    "app_data['FAC_Sum'] = 0\n",
    "for var in res.params.keys(): \n",
    "    app_data[var+'_FAC'] = (app_data[var+'_FAC_ratio'] - 1) * app_data['UPT_ADJ_base']\n",
    "    app_data['FAC_Sum'] = app_data['FAC_Sum'] + app_data[var+'_FAC']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total FAC is based on the fitted model (applied multiplicitively)\n",
    "app_data['Known_FAC'] = (app_data['fitted_exp_ratio'] - 1) * app_data['UPT_ADJ_base']\n",
    "\n",
    "# uknown change is the difference between the observed change and the known change\n",
    "app_data['Unknown_FAC'] = app_data['UPT_ADJ_diff'] - app_data['Known_FAC']\n",
    "\n",
    "# the change in ridership associated new systems\n",
    "app_data['New_Reporter_FAC'] = app_data['UPT_ADJ_new_reporter'] \n",
    "\n",
    "# should be teh same as UPT_ADJ_DIFF\n",
    "app_data['Total_Change'] = app_data['Known_FAC'] + app_data['Unknown_FAC'] + app_data['New_Reporter_FAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate APTA - 4 groups\n",
    "app_data['CLUSTER_APTA4'] = np.floor(app_data['CLUSTER_APTA']/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index so I get ID and year\n",
    "app_data = app_data.reset_index()\n",
    "app_data = app_data.rename(columns={'level_0' : 'ID', 'level_1' : 'Year'})\n",
    "app_data.to_csv('FAC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the fields we keep\n",
    "out_fields = ['ID', 'Year', 'RAIL_FLAG', \n",
    "              'CLUSTER_APTA', 'CLUSTER_APTA4',    \n",
    "              'UPT_ADJ_first_year', \n",
    "              'UPT_ADJ_base', 'UPT_ADJ', 'UPT_ADJ_diff', \n",
    "              'fitted_exp', 'fitted_exp_diff']\n",
    "\n",
    "# exogenous variables \n",
    "for var in res.params.keys(): \n",
    "    out_var = var.replace('_log', '')\n",
    "    out_fields = out_fields + [out_var]\n",
    "    \n",
    "# FAC\n",
    "for var in res.params.keys(): \n",
    "    out_fields = out_fields + [var+'_FAC']\n",
    "out_fields = out_fields + ['FAC_Sum', 'Known_FAC', 'Unknown_FAC', 'New_Reporter_FAC', 'Total_Change']\n",
    "    \n",
    "# keep those fields\n",
    "summary_data = app_data.reset_index()[out_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take weighted average of exogenous variables\n",
    "for var in res.params.keys(): \n",
    "    out_var = var.replace('_log', '')\n",
    "    summary_data[out_var] = summary_data[out_var] * summary_data['UPT_ADJ_first_year']\n",
    "\n",
    "# aggregate to bus/rail totals\n",
    "summary_data_apta4 = summary_data.groupby(by=['CLUSTER_APTA4', 'RAIL_FLAG', 'Year']).agg('sum')\n",
    "\n",
    "# divide for weighted averages\n",
    "for var in res.params.keys(): \n",
    "    out_var = var.replace('_log', '')\n",
    "    summary_data_apta4[out_var] = summary_data_apta4[out_var] / summary_data_apta4['UPT_ADJ_first_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_data_apta4.to_csv('FAC_totals_APTA4_CLUSTERS.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
