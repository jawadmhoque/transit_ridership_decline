{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = r'D:\\UoK\\OneDrive - University of Kentucky\\github\\Transit_ridership\\transit_ridership_decline\\Factors and Ridership Data\\code'\n",
    "load_data = r'D:\\UoK\\OneDrive - University of Kentucky\\github\\Transit_ridership\\transit_ridership_decline\\Factors and Ridership Data\\Model Estimation\\Est4'\n",
    "output_folder = r'D:\\UoK\\OneDrive - University of Kentucky\\github\\Transit_ridership\\transit_ridership_decline\\Factors and Ridership Data\\Script Outputs'\n",
    "folder_path = ''\n",
    "file_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Cumulative_Graphs(_df, _clustername, _file_name, _chartinitials):    \n",
    "    df = _df\n",
    "    # get dataset's file name\n",
    "    file_name = _file_name\n",
    "    # Define columns    \n",
    "    clusters_col = _clustername\n",
    "    # charname = 'FAC_totals_GT_CLUSTERS'\n",
    "    chartinitials = _file_name+'_cumsum'\n",
    "    # set folder  path\n",
    "    folder_path = _file_name+'_cumsum' \n",
    "    # df, CLUSTER_GT_NEW_11, FAC_totals_GT_CLUSTERS\n",
    "    prepare_charts(df,clusters_col,chartinitials,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, CLUSTER_GT_8_GROUPS, FAC_totals_gt_grouped_CLUSTERS\n",
    "def prepare_charts(_df, _clustercolumn, _charinitials,_file_name):\n",
    "    df = _df\n",
    "    clustercolumn = _clustercolumn\n",
    "    chartinitials = _charinitials\n",
    "    folder_path = _file_name\n",
    "    # get unique clusters\n",
    "    clusters = df[clustercolumn].unique()\n",
    "    clusters.sort()\n",
    "    # get unique modes\n",
    "    df.rename(columns={'RAIL_FLAG': 'Mode'}, inplace=True)\n",
    "    modes = df['Mode'].unique()\n",
    "    modes.sort()\n",
    "    # get unique years\n",
    "    years = df['Year'].unique()\n",
    "    years.sort()      \n",
    "\n",
    "    for cluster in clusters:        \n",
    "        df_fltr = df[df[clustercolumn] == cluster]\n",
    "        # Print the cluster \n",
    "        col_index = df_fltr.columns.get_loc(clustercolumn)\n",
    "        cluster_code = str(df_fltr.iloc[0, col_index])\n",
    "        print('Cluster Code:' + str(cluster_code))\n",
    "        df_fltr['Year'] = pd.to_datetime(df_fltr['Year'].astype(str), format='%Y')\n",
    "        df_fltr_mod = df_fltr.set_index(pd.DatetimeIndex(df_fltr['Year']).year)\n",
    "        \n",
    "        for mode in modes:            \n",
    "            if mode == 0:\n",
    "                mode_name = \"BUS\"\n",
    "            else:\n",
    "                mode_name = \"RAIL\"\n",
    "                \n",
    "            # get number of sub-plots defined - 4*2 means 4 rows having 2 graphs (each sized 18x9) in each row = 8 graphs\n",
    "            fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(18, 9), constrained_layout=True)        \n",
    "            x = 1            \n",
    "            df_fltr_mode = df_fltr_mod[df_fltr_mod.Mode == mode]            \n",
    "            \n",
    "            # Year vs Total_FAC_Scaled --> Graph (0,0)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_Total_FAC_cumsum', label='UPT_ADJ - Total_FAC_cumsum', ax=ax[0][0], legend=True)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='Observed Rdrship', ax=ax[0][0], legend=True, color='black', linewidth=3)\n",
    "            ax[0][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_Total_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_Total_FAC_cumsum'].values>=df_fltr_mode['UPT_ADJ'].values, facecolor='green', interpolate=True, alpha=0.5)\n",
    "            ax[0][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_Total_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_Total_FAC_cumsum'].values<df_fltr_mode['UPT_ADJ'].values, facecolor='red', interpolate=True, alpha=0.5)\n",
    "            ax[0][0].set(xlabel=\"Years\", ylabel='Total_FAC')\n",
    "            ax[0][0].legend(loc='best') \n",
    "\n",
    "            # Year vs Total_FAC_Scaled --> Graph (1,0)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_POP_EMP_log_FAC_cumsum', label='UPT_ADJ - POP_EMP_log_FAC_cumsum', ax=ax[1][0], legend=True)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='Observed Rdrship', ax=ax[1][0], legend=True, color='black', linewidth=3)\n",
    "            ax[1][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_POP_EMP_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_POP_EMP_log_FAC_cumsum'].values>=df_fltr_mode['UPT_ADJ'].values, facecolor='green', interpolate=True, alpha=0.5)\n",
    "            ax[1][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_POP_EMP_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_POP_EMP_log_FAC_cumsum'].values<df_fltr_mode['UPT_ADJ'].values, facecolor='red', interpolate=True, alpha=0.5)     \n",
    "            ax[1][0].set(xlabel=\"Years\", ylabel='POP_EMP')\n",
    "            ax[1][0].legend(loc='best')\n",
    "\n",
    "\n",
    "            # Year vs Total_FAC_Scaled --> Graph (2,0)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_TSD_POP_PCT_FAC_cumsum', label='UPT_ADJ - TSD_POP_PCT_FAC_cumsum', ax=ax[2][0], legend=True)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='Observed Rdrship', ax=ax[2][0], legend=True, color='black', linewidth=3)\n",
    "            ax[2][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_TSD_POP_PCT_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_TSD_POP_PCT_FAC_cumsum'].values>=df_fltr_mode['UPT_ADJ'].values, facecolor='green', interpolate=True, alpha=0.5)\n",
    "            ax[2][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_TSD_POP_PCT_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_TSD_POP_PCT_FAC_cumsum'].values<df_fltr_mode['UPT_ADJ'].values, facecolor='red', interpolate=True, alpha=0.5)\n",
    "            ax[2][0].set(xlabel=\"Years\", ylabel='TSD_POP_PCT')\n",
    "            ax[2][0].legend(loc='best')       \n",
    "\n",
    "\n",
    "            # Year vs Total_FAC_Scaled --> Graph (3,0)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_PCT_HH_NO_VEH_FAC_cumsum', label='UPT_ADJ - TSD_POP_PCT_FAC_cumsum', ax=ax[3][0], legend=True)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='Observed Rdrship', ax=ax[3][0], legend=True, color='black', linewidth=3)\n",
    "            ax[3][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_PCT_HH_NO_VEH_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_PCT_HH_NO_VEH_FAC_cumsum'].values>=df_fltr_mode['UPT_ADJ'].values, facecolor='green', interpolate=True, alpha=0.5)\n",
    "            ax[3][0].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_PCT_HH_NO_VEH_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_TSD_POP_PCT_FAC_cumsum'].values<df_fltr_mode['UPT_ADJ'].values, facecolor='red', interpolate=True, alpha=0.5)\n",
    "            ax[3][0].set(xlabel=\"Years\", ylabel='PCT_HH_NO_VEH')\n",
    "            ax[3][0].legend(loc='best')      \n",
    "\n",
    "\n",
    "            # Year vs Total_FAC_Scaled --> Graph (0,1)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_VRM_ADJ_log_FAC_cumsum', label='UPT_ADJ - VRM_ADJ_log_FAC_cumsum', ax=ax[0][1], legend=True)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='Observed Rdrship', ax=ax[0][1], legend=True, color='black', linewidth=3)\n",
    "            ax[0][1].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_VRM_ADJ_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_VRM_ADJ_log_FAC_cumsum'].values>=df_fltr_mode['UPT_ADJ'].values, facecolor='green', interpolate=True, alpha=0.5)\n",
    "            ax[0][1].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_VRM_ADJ_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_VRM_ADJ_log_FAC_cumsum'].values<df_fltr_mode['UPT_ADJ'].values, facecolor='red', interpolate=True, alpha=0.5)\n",
    "            ax[0][1].set(xlabel=\"Years\", ylabel='VRM_ADJ')\n",
    "            ax[0][1].legend(loc='best')            \n",
    "            \n",
    "            \n",
    "            # Year vs Total_FAC_Scaled --> Graph (1,1)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_GasPrice_log_FAC_cumsum', label='UPT_ADJ - GasPrice_log_FAC_cumsum', ax=ax[1][1], legend=True)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='Observed Rdrship', ax=ax[1][1], legend=True, color='black', linewidth=3)\n",
    "            ax[1][1].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_GasPrice_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_GasPrice_log_FAC_cumsum'].values>=df_fltr_mode['UPT_ADJ'].values, facecolor='green', interpolate=True, alpha=0.5)\n",
    "            ax[1][1].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_GasPrice_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_GasPrice_log_FAC_cumsum'].values<df_fltr_mode['UPT_ADJ'].values, facecolor='red', interpolate=True, alpha=0.5)\n",
    "            ax[1][1].set(xlabel=\"Years\", ylabel='GasPrice')\n",
    "            ax[1][1].legend(loc='best')            \n",
    "            \n",
    "            \n",
    "            # Year vs Total_FAC_Scaled --> Graph (2,1)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_FARE_per_UPT_log_FAC_cumsum', label='UPT_ADJ - FARE_per_UPT_log_FAC_cumsum', ax=ax[2][1], legend=True)\n",
    "            df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='Observed Rdrship', ax=ax[2][1], legend=True, color='black', linewidth=3)\n",
    "            ax[2][1].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_FARE_per_UPT_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_FARE_per_UPT_log_FAC_cumsum'].values>=df_fltr_mode['UPT_ADJ'].values, facecolor='green', interpolate=True, alpha=0.5)\n",
    "            ax[2][1].fill_between(df_fltr_mode['Year'].values,df_fltr_mode['UPT_ADJ_FARE_per_UPT_log_FAC_cumsum'].values,df_fltr_mode['UPT_ADJ'].values,  where=df_fltr_mode['UPT_ADJ_FARE_per_UPT_log_FAC_cumsum'].values<df_fltr_mode['UPT_ADJ'].values, facecolor='red', interpolate=True, alpha=0.5)\n",
    "            ax[2][1].set(xlabel=\"Years\", ylabel='FARE_per_UPT')\n",
    "            ax[2][1].legend(loc='best')\n",
    "            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (3,1)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='TSD_POP_PCT_FAC_cumsum', label='UPT_ADJ - TSD_POP_PCT_FAC_cumsum', ax=ax[3][1], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label='UPT_ADJ', ax=ax[3][1], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[3][1].set(xlabel=\"Years\", ylabel='TSD_POP_PCT')\n",
    "#             ax[3][1].legend(loc='best')\n",
    "            fig.suptitle(('Cluster Code:' + str(cluster_code) + \"-\" + str(mode)),fontsize=14)\n",
    "            fig.tight_layout()\n",
    "            _figno = x\n",
    "            # code to let these file save in the specific folder\n",
    "            os.chdir(output_folder)\n",
    "            # add folder name\n",
    "    #         save_folder = output_folder +'\\\\' + folder_path\n",
    "            os.path.join(output_folder, folder_path)\n",
    "            \n",
    "            if not os.path.exists(os.path.join(output_folder, folder_path)):\n",
    "                os.mkdir(folder_path)\n",
    "                print (folder_path + \" for \" + mode_name+\" : sucessfully created\")\n",
    "            else:\n",
    "                print (folder_path + \" for \" + mode_name+\" : already exists\")\n",
    "            \n",
    "            mod = output_folder + \"\\\\\" + str(folder_path)\n",
    "            os.chdir(mod)\n",
    "            fig.savefig((\"Fig \"+ str(_figno) + \"-\" + cluster_code + \" - \" + mode_name + \".png\"))\n",
    "            plt.suptitle(cluster_code,fontsize=14)\n",
    "            plt.close(fig)\n",
    "            x += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAC_totals_GT_CLUSTERS():\n",
    "    # create cumulative column and update the column\n",
    "    os.chdir(load_data)\n",
    "    df_org = pd.read_csv('FAC_totals_GT_CLUSTERS.csv')\n",
    "    # list(df.columns)\n",
    "    # create new columsn\n",
    "    col_name = ['VRM_ADJ_log_FAC','FARE_per_UPT_log_FAC','POP_EMP_log_FAC','GasPrice_log_FAC','PCT_HH_NO_VEH_FAC','TSD_POP_PCT_FAC','Total_FAC']\n",
    "    cum_col = []\n",
    "    col_UPT_ADJ = ['UPT_ADJ']\n",
    "\n",
    "    for col in col_name:\n",
    "        df_org[str(col)+'_cumsum'] = df_org[col]\n",
    "        cum_col.append(str(col)+'_cumsum')\n",
    "    \n",
    "    cluster_values =\"CLUSTER_GT_NEW_11\"\n",
    "    folder_name = \"UPT_FAC_totals_GT_CLUSTERS\"\n",
    "    chart_name = \"UPT_FAC_totals_GT_CLUSTERS\"\n",
    "\n",
    "    # # for each cluster_id get the cumulative addition starting from 2002-->2018\n",
    "    # os.chdir(output_folder)\n",
    "    for col in cum_col:\n",
    "        df_org[col] = df_org.groupby(['CLUSTER_GT_NEW_11','RAIL_FLAG'])[col].cumsum()\n",
    "\n",
    "    # # create a new column which is diff between UPT_ADJ - CUMSUM colmn\n",
    "    for col in cum_col:\n",
    "         df_org['UPT_ADJ_' + str(col)] = df_org['UPT_ADJ'] - df_org[col]\n",
    "\n",
    "    df_org.to_csv(folder_name+'.csv')      \n",
    "    # Create_Cumulative_Graphs(dataframe, cluster_values, folder_name, chart_name)\n",
    "    Create_Cumulative_Graphs(df_org,cluster_values,folder_name,chart_name)\n",
    "    # prepare_charts(df_org,clusters_col,chartinitials,file_name)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAC_totals_gt_grouped_CLUSTERS():\n",
    "    # create cumulative column and update the column\n",
    "    os.chdir(load_data)\n",
    "    df_org = pd.read_csv('FAC_totals_gt_grouped_CLUSTERS.csv')\n",
    "    # list(df.columns)\n",
    "    # create new columsn\n",
    "    col_name = ['VRM_ADJ_log_FAC','FARE_per_UPT_log_FAC','POP_EMP_log_FAC','GasPrice_log_FAC','PCT_HH_NO_VEH_FAC','TSD_POP_PCT_FAC','Total_FAC']\n",
    "    cum_col = []\n",
    "    col_UPT_ADJ = ['UPT_ADJ']\n",
    "\n",
    "    for col in col_name:\n",
    "        df_org[str(col)+'_cumsum'] = df_org[col]\n",
    "        cum_col.append(str(col)+'_cumsum')\n",
    "        \n",
    "    cluster_values =\"CLUSTER_GT_8_GROUPS\"\n",
    "    folder_name = \"UPT_FAC_totals_gt_grouped_CLUSTERS\"\n",
    "    chart_name = \"UPT_FAC_totals_gt_grouped_CLUSTERS\"\n",
    "\n",
    "    # # for each cluster_id get the cumulative addition starting from 2002-->2018\n",
    "    # os.chdir(output_folder)\n",
    "    for col in cum_col:\n",
    "        df_org[col] = df_org.groupby([cluster_values,'RAIL_FLAG'])[col].cumsum()\n",
    "\n",
    "    # # create a new column which is diff between UPT_ADJ - CUMSUM colmn\n",
    "    for col in cum_col:\n",
    "         df_org['UPT_ADJ_' + str(col)] = df_org['UPT_ADJ'] - df_org[col]\n",
    "            \n",
    "    # Create_Cumulative_Graphs(dataframe, cluster_values, folder_name, chart_name)\n",
    "    Create_Cumulative_Graphs(df_org,cluster_values,folder_name,chart_name)\n",
    "    # prepare_charts(df_org,clusters_col,chartinitials,file_name)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAC_totals_APTA_CLUSTERS():\n",
    "    # create cumulative column and update the column\n",
    "    os.chdir(load_data)\n",
    "    df_org = pd.read_csv('FAC_totals_APTA_CLUSTERS.csv')\n",
    "    # list(df.columns)\n",
    "    # create new columsn\n",
    "    col_name = ['VRM_ADJ_log_FAC','FARE_per_UPT_log_FAC','POP_EMP_log_FAC','GasPrice_log_FAC','PCT_HH_NO_VEH_FAC','TSD_POP_PCT_FAC','Total_FAC']\n",
    "    cum_col = []\n",
    "    col_UPT_ADJ = ['UPT_ADJ']\n",
    "\n",
    "    for col in col_name:\n",
    "        df_org[str(col)+'_cumsum'] = df_org[col]\n",
    "        cum_col.append(str(col)+'_cumsum')\n",
    "        \n",
    "    cluster_values =\"CLUSTER_APTA\"\n",
    "    folder_name = \"UPT_FAC_totals_APTA_CLUSTERS\"\n",
    "    chart_name = \"UPT_FAC_totals_APTA_CLUSTERS\"\n",
    "\n",
    "    # # for each cluster_id get the cumulative addition starting from 2002-->2018\n",
    "    # os.chdir(output_folder)\n",
    "    for col in cum_col:\n",
    "        df_org[col] = df_org.groupby([cluster_values,'RAIL_FLAG'])[col].cumsum()\n",
    "\n",
    "    # # create a new column which is diff between UPT_ADJ - CUMSUM colmn\n",
    "    for col in cum_col:\n",
    "         df_org['UPT_ADJ_' + str(col)] = df_org['UPT_ADJ'] - df_org[col]\n",
    "            \n",
    "    # Create_Cumulative_Graphs(dataframe, cluster_values, folder_name, chart_name)\n",
    "    Create_Cumulative_Graphs(df_org,cluster_values,folder_name,chart_name)\n",
    "    # prepare_charts(df_org,clusters_col,chartinitials,file_name)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FAC_totals_apta_grouped_CLUSTERS():\n",
    "    # create cumulative column and update the column\n",
    "    os.chdir(load_data)\n",
    "    df_org = pd.read_csv('FAC_totals_apta_grouped_CLUSTERS.csv')\n",
    "    # list(df.columns)\n",
    "    # create new columsn\n",
    "    col_name = ['VRM_ADJ_log_FAC','FARE_per_UPT_log_FAC','POP_EMP_log_FAC','GasPrice_log_FAC','PCT_HH_NO_VEH_FAC','TSD_POP_PCT_FAC','Total_FAC']\n",
    "    cum_col = []\n",
    "    col_UPT_ADJ = ['UPT_ADJ']\n",
    "\n",
    "    for col in col_name:\n",
    "        df_org[str(col)+'_cumsum'] = df_org[col]\n",
    "        cum_col.append(str(col)+'_cumsum')\n",
    "        \n",
    "    cluster_values =\"CLUSTER_APTA_GROUPED\"\n",
    "    folder_name = \"UPT_FAC_totals_apta_grouped_CLUSTERS\"\n",
    "    chart_name = \"UPT_FAC_totals_apta_grouped_CLUSTERS\"\n",
    "\n",
    "    # # for each cluster_id get the cumulative addition starting from 2002-->2018\n",
    "    # os.chdir(output_folder)\n",
    "    for col in cum_col:\n",
    "        df_org[col] = df_org.groupby([cluster_values,'RAIL_FLAG'])[col].cumsum()\n",
    "\n",
    "    # # create a new column which is diff between UPT_ADJ - CUMSUM colmn\n",
    "    for col in cum_col:\n",
    "         df_org['UPT_ADJ_' + str(col)] = df_org['UPT_ADJ'] - df_org[col]\n",
    "            \n",
    "    # Create_Cumulative_Graphs(dataframe, cluster_values, folder_name, chart_name)\n",
    "    Create_Cumulative_Graphs(df_org,cluster_values,folder_name,chart_name)\n",
    "    # prepare_charts(df_org,clusters_col,chartinitials,file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Code:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: This figure was using constrained_layout==True, but that is incompatible with subplots_adjust and or tight_layout: setting constrained_layout==False. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:2\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:3\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:4\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:5\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:6\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:7\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:8\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:9\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:10\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:11\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:100\n",
      "UPT_FAC_totals_GT_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_GT_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:100\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:A\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:B\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:C\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:D\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:E\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:F\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:G\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:H\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_gt_grouped_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:10.0\n",
      "UPT_FAC_totals_APTA_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_APTA_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:21.0\n",
      "UPT_FAC_totals_APTA_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_APTA_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:22.0\n",
      "UPT_FAC_totals_APTA_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_APTA_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:23.0\n",
      "UPT_FAC_totals_APTA_CLUSTERS for BUS : already exists\n",
      "UPT_FAC_totals_APTA_CLUSTERS for RAIL : already exists\n",
      "Cluster Code:24.0\n",
      "UPT_FAC_totals_APTA_CLUSTERS for BUS : already exists\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    FAC_totals_GT_CLUSTERS()\n",
    "    FAC_totals_gt_grouped_CLUSTERS()\n",
    "    FAC_totals_APTA_CLUSTERS()\n",
    "    FAC_totals_apta_grouped_CLUSTERS()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df, CLUSTER_GT_8_GROUPS, FAC_totals_gt_grouped_CLUSTERS\n",
    "# def prepare_charts(_df, _clustercolumn, _charinitials,_file_name):\n",
    "#     df = _df\n",
    "#     clustercolumn = _clustercolumn\n",
    "#     chartinitials = _charinitials\n",
    "#     folder_path = _file_name\n",
    "#     # get unique clusters\n",
    "#     clusters = df[clustercolumn].unique()\n",
    "#     clusters.sort()\n",
    "#     # get unique modes\n",
    "#     df.rename(columns={'RAIL_FLAG': 'Mode'}, inplace=True)\n",
    "#     modes = df['Mode'].unique()\n",
    "#     modes.sort()\n",
    "#     # get unique years\n",
    "#     years = df['Year'].unique()\n",
    "#     years.sort()      \n",
    "\n",
    "#     for cluster in clusters:        \n",
    "#         df_fltr = df[df[clustercolumn] == cluster]\n",
    "#         # Print the cluster \n",
    "#         col_index = df_fltr.columns.get_loc(clustercolumn)\n",
    "#         cluster_code = str(df_fltr.iloc[0, col_index])\n",
    "#         print('Cluster Code:' + str(cluster_code))\n",
    "#         df_fltr['Year'] = pd.to_datetime(df_fltr['Year'].astype(str), format='%Y')\n",
    "#         df_fltr_mod = df_fltr.set_index(pd.DatetimeIndex(df_fltr['Year']).year)        \n",
    "#         # get number of sub-plots defined - 4*2 means 4 rows having 2 graphs (each sized 18x9) in each row = 8 graphs\n",
    "#         fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(18, 9))        \n",
    "#         x = 1\n",
    "#         # col_name = ['UPT_ADJ_VRM_ADJ_log_FAC_cumsum','UPT_ADJ_FARE_per_UPT_log_FAC_cumsum','UPT_ADJ_POP_EMP_log_FAC_cumsum','UPT_ADJ_GasPrice_log_FAC_cumsum','UPT_ADJ_PCT_HH_NO_VEH_FAC_cumsum','UPT_ADJ_TSD_POP_PCT_FAC_cumsum','UPT_ADJ_Total_FAC_cumsum']\n",
    "#         for mode in modes:\n",
    "#             df_fltr_mode = df_fltr_mod[df_fltr_mod.Mode == mode]            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (0,0)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ_Total_FAC_cumsum', label=str(mode), ax=ax[0][0], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[0][0], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[0][0].set(xlabel=\"Years\", ylabel='Total_FAC_cumsum')\n",
    "#             ax[0][0].legend(loc='best')            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (1,0)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='POP_EMP_log_FAC_cumsum', label=str(mode), ax=ax[1][0], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[1][0], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[1][0].set(xlabel=\"Years\", ylabel='POP_EMP_log_FAC_cumsum')\n",
    "#             ax[1][0].legend(loc='best')            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (2,0)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='TSD_POP_PCT_FAC_cumsum', label=str(mode), ax=ax[2][0], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[2][0], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[2][0].set(xlabel=\"Years\", ylabel='TSD_POP_PCT_FAC_cumsum')\n",
    "#             ax[2][0].legend(loc='best')            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (3,0)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='PCT_HH_NO_VEH_FAC_cumsum', label=str(mode), ax=ax[3][0], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[3][0], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[3][0].set(xlabel=\"Years\", ylabel='PCT_HH_NO_VEH_FAC_cumsum')\n",
    "#             ax[3][0].legend(loc='best')            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (0,1)\n",
    "# #             df_fltr_mode.groupby('Mode').plot(x='Year', y='', label=str(mode), ax=ax[0][1], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "# #             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[0][0], legend=True, marker='',color='olive',linewidth=2)\n",
    "# #             ax[0][1].set(xlabel=\"Years\", ylabel='')\n",
    "# #             ax[0][1].legend(loc='best')            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (1,1)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='GasPrice_log_FAC_cumsum', label=str(mode), ax=ax[1][1], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[1][1], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[1][1].set(xlabel=\"Years\", ylabel='GasPrice_log_FAC_cumsum')\n",
    "#             ax[1][1].legend(loc='best')            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (2,1)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='FARE_per_UPT_log_FAC_cumsum', label=str(mode), ax=ax[2][1], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[2][1], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[2][1].set(xlabel=\"Years\", ylabel='FARE_per_UPT_log_FAC_cumsum')\n",
    "#             ax[2][1].legend(loc='best')            \n",
    "#             # Year vs Total_FAC_Scaled --> Graph (3,1)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='TSD_POP_PCT_FAC_cumsum', label=str(mode), ax=ax[3][1], legend=True, marker='',color='skyblue',linewidth=2)\n",
    "#             df_fltr_mode.groupby('Mode').plot(x='Year', y='UPT_ADJ', label=str(mode), ax=ax[3][1], legend=True, marker='',color='olive',linewidth=2)\n",
    "#             ax[3][1].set(xlabel=\"Years\", ylabel='TSD_POP_PCT_FAC_cumsum')\n",
    "#             ax[3][1].legend(loc='best')                        \n",
    "#         fig.suptitle(('Cluster Code:' + str(cluster_code)),fontsize=14)\n",
    "#         fig.tight_layout()\n",
    "#         _figno = x\n",
    "\n",
    "#         # code to let these file save in the specific folder\n",
    "#         os.chdir(output_folder)\n",
    "#         # add folder name\n",
    "# #         save_folder = output_folder +'\\\\' + folder_path\n",
    "#         os.path.join(output_folder, folder_path)\n",
    "#         if not os.path.exists(os.path.join(output_folder, folder_path)):\n",
    "#             os.mkdir(folder_path)\n",
    "#             print (folder_path + \": sucessfully created\")\n",
    "#         else:\n",
    "#             print (folder_path + \": already exists\")\n",
    "            \n",
    "#         mod = output_folder + \"\\\\\" + str(folder_path)\n",
    "#         os.chdir(mod)\n",
    "#         fig.savefig((\"Fig \" + str(_figno) + \"-\" + cluster_code + \".png\"))\n",
    "#         plt.suptitle(cluster_code,fontsize=14)\n",
    "#         plt.close(fig)\n",
    "#         x += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_name = ['VRM_ADJ_log_FAC','FARE_per_UPT_log_FAC','POP_EMP_log_FAC','GasPrice_log_FAC','PCT_HH_NO_VEH_FAC','TSD_POP_PCT_FAC','Total_FAC']\n",
    "# cum_col = []\n",
    "\n",
    "# for col in col_name:\n",
    "#     df[str(col)+'_cum'] = df[col]\n",
    "#     cum_col.append(str(col)+'_cum')\n",
    "\n",
    "# list(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(cum_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #aggregate sum to all columns\n",
    "# df1 = df.groupby(['CLUSTER_GT_NEW_11','RAIL_FLAG','Year', 'CLUSTER_GT_ORIGINAL', 'CLUSTER_APTA', 'CLUSTER_APTA_GROUPED']).sum()\n",
    "# # df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #aggregate cumcum to Usage column only \n",
    "# s = df1.groupby(level=0)['VRM_ADJ_log_FAC_cum','FARE_per_UPT_log_FAC_cum','POP_EMP_log_FAC_cum','GasPrice_log_FAC_cum','PCT_HH_NO_VEH_FAC_cum','TSD_POP_PCT_FAC_cum','Total_FAC_cum'].cumsum()\n",
    "# # print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #join cumsum series to aggregate df1\n",
    "# df3 = df1.join(s, rsuffix='_cumsum').reset_index()\n",
    "# os.chdir(output_folder)\n",
    "# df3.to_csv(\"sample.csv\")\n",
    "# # print (df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumsum_col = ['VRM_ADJ_log_FAC_cum','FARE_per_UPT_log_FAC_cum','POP_EMP_log_FAC_cum','GasPrice_log_FAC_cum','PCT_HH_NO_VEH_FAC_cum','TSD_POP_PCT_FAC_cum','Total_FAC_cum']\n",
    "# df2 = df.groupby(by=['CLUSTER_GT_NEW_11','RAIL_FLAG','Year', 'CLUSTER_GT_ORIGINAL', 'CLUSTER_APTA', 'CLUSTER_APTA_GROUPED'], sort=False).sum()\n",
    "# cols = [col for col in df2.columns if col != cumsum_col]\n",
    "# df1 = df2.set_index(cols, append=True).groupby(level=[0]).cumsum()\n",
    "# df1 = df2.assign(Usage_cumsum = df1.reset_index(level=2, drop=True)).reset_index()\n",
    "# print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_for_differencing = ['a']\n",
    "# df1 = df.copy()[df.columns.difference(columns_for_differencing)]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
