{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-249921ed6847>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m from pandas.io.api import (\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;31m# excel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0mExcelFile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgbq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_gbq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpackers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_msgpack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_msgpack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_parquet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_json\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdumps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_table_schema\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_table_schema\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m __all__ = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_normalize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvert_to_line_delimits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_table_schema\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_table_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_table_schema\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mloads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# input to the this file is the final merged (stage 3.csv) file which is used to get the charts \n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the final merged dataset file\n",
    "os.chdir(r'D:\\UoK\\OneDrive - University of Kentucky\\github\\transit_ridership_decline\\Factors and Ridership Data\\Shared_dataset')\n",
    "df = pd.read_csv('merged_df_3.csv')\n",
    "modes = df['Mode'].unique()\n",
    "modes.sort()\n",
    "colnames = ['UPT_ADJ', 'VRM_ADJ', 'VRH_ADJ', 'FARE_TOTAL', 'FARE_per_UPT', 'AVG_SPEED']\n",
    "for _mode in modes:    \n",
    "    for col in colnames:\n",
    "        colName = _mode + \"_\" + col\n",
    "        df[colName] = np.where(df['Mode'] ==str(_mode), df[str(col)],0)\n",
    "        \n",
    "df.to_csv('modified_dataset.csv')\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = df['Mode'].unique()\n",
    "modes.sort()\n",
    "colnames = ['UPT_ADJ', 'VRM_ADJ', 'VRH_ADJ', 'FARE_TOTAL', 'FARE_per_UPT', 'AVG_SPEED']\n",
    "for _mode in modes:    \n",
    "    for col in colnames:\n",
    "        colName = _mode + \"_\" + col\n",
    "        df[colName] = np.where(df['Mode'] ==str(_mode), df[str(col)],0)\n",
    "        \n",
    "df.to_csv('modified_dataset.csv')\n",
    "print(\"Success\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query dataset and create new columns for bus_vrm and rail_vrms\n",
    "for col in data.columns: \n",
    "    print(col)\n",
    "    \n",
    "\n",
    "modes = df['Mode'].unique()\n",
    "modes.sort()\n",
    "for _mode in modes:\n",
    "    colName = _mode + \"_\" + \"VRM\"\n",
    "    df[colName] = np.where(df['Mode'] ==str(_mode), df['VRM'],0)\n",
    "    # Also generate difference between nth row and (n-1) row. NB: zeroth row is constant\n",
    "    df[colName+'_difference'] = df[colName] - df[colName].shift(-1)\n",
    "#     df['log_value'] = np.where((df[str(_mode)+'_difference']>0),np.log(df[str(_mode)+'_difference']),0)\n",
    "# df = df.drop(columns=['VRM'])\n",
    "\n",
    "df.to_csv('modified_dataset.csv')\n",
    "print(\"Success\")\n",
    "\n",
    "\n",
    "# # Create new columns Rail_VRM and Bus_VRM\n",
    "# mode = \"Rail\"\n",
    "# colName = \"Rail\" + \"_\" + \"VRM\"\n",
    "# df[colName] = np.where(df['Mode'] =='Rail', df['VRM'],0)\n",
    "# # Also generate difference between nth row and (n-1) row. NB: zeroth row is constant\n",
    "# df['rail_difference'] = df[colName].shift(+1) - df[colName]\n",
    "# df['log_value'] = np.log(df['rail_difference'])\n",
    "\n",
    "# colName = \"Bus\" + \"_\" + \"VRM\"\n",
    "# df[colName] = np.where(df['Mode'] =='Bus', df['VRM'],0)\n",
    "# df['bus_difference'] = df[colName].shift(+1) - df[colName]\n",
    "# df = df.drop(columns=['VRM'])\n",
    "# df.to_csv('modified_dataset.csv')\n",
    "# print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get unique CBSAs\n",
    "# yrs = df['Year'].unique()\n",
    "# yrs.sort()\n",
    "# id2s = df['CBSA'].unique()\n",
    "# id2s.sort()\n",
    "# results = []\n",
    "\n",
    "# df['UPT'] = np.where(merged_df_3['UPT'].isnull(), '0', merged_df_3['UPT'])\n",
    "# # result_df= df[df['Mode'].str.contains(\"Rail\")]\n",
    "# # strMode = \"Rail\"\n",
    "# # colName = strMode + \"_\" + \"VRM\"\n",
    "# # # rename the columns\n",
    "# # result_df.rename(columns={'VRM': colName}, inplace=True)\n",
    "# # result_df.head(50)\n",
    "# dfObj = pd.DataFrame()\n",
    "# # query dataset and create new columns for bus_vrm and rail_vrms\n",
    "# modes = df['Mode'].unique()\n",
    "# modes.sort()\n",
    "# for _mode in modes:\n",
    "#     strMode = str(_mode)\n",
    "#     colName = strMode + \"_\" + \"VRM\"\n",
    "#     df[colName] = np.where(df['Mode'].isnull(), '0', merged_df_3['UPT'])\n",
    "#     result_df= df[df['Mode'].str.contains(strMode)]\n",
    "#     merged_df_3['UPT'] = np.where(merged_df_3['UPT'].isnull(), '0', merged_df_3['UPT'])\n",
    "#     df[colName] = df['UPT'].isnull(), '0', merged_df_3['UPT'])\n",
    "    \n",
    "#     # rename the columns\n",
    "#     result_df.rename(columns={'VRM': colName}, inplace=True)\n",
    "#     result_dict = result_df.to_dict('split')\n",
    "#     results.append(result_dict)\n",
    "    \n",
    "    \n",
    "# pd.DataFrame(results).to_csv(output_filename)\n",
    "# print(\"Success\")\n",
    "            \n",
    "# # output_filename = 'modified_dataset.csv'\n",
    "# # dfObj.to_csv(output_filename)\n",
    "# # print(\"Success\")\n",
    "\n",
    "# # # # loop each cbsa and create new rail_vrms and bus_vrms\n",
    "# # # for _id2s in id2s:    \n",
    "# # #     # get unique modes in the city\n",
    "# # #     modes = df['Mode'].unique()\n",
    "# # #     modes.sort()\n",
    "# # #     for _mode in modes:\n",
    "# # #         strMode = str(_mode)\n",
    "# # #         result_df= df[df['Mode'].str.contains(strMode)]\n",
    "# # #         # rename the columns\n",
    "# # #         result_df.rename(columns={'VRM': (strMode + '_'+'VRM')}, inplace=True)\n",
    "# # #         result_dict = result_df.to_dict()\n",
    "# # #         results.append(result_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "# # # df_mod = pd.Dataframe(results)\n",
    "# # # print(df_mod)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
